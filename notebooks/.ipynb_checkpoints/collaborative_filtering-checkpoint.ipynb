{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This is a second part of a two part series. The data preparation was done in the [first part](https://github.com/PMMAraujo/OnlineRetailII-ecommerce-project/blob/master/notebooks/eda_and_content_based.ipynb), namely cleaning the data, imputation of some user ids and the conversion of the bought quantities to log(x+1)). The objective in this part is to create some collaborative filtering recommender systems! However, instead of using the usual types of user-item interactions, like ratings, here the dependent variable is the quantity bought by users of said item. \n",
    "Recommender systems are consentualy divided into two main categories: Content Based and Collaborative Filtering. The base in which these methodologies build upon is that knowing the similarities between users and items we can recommend similar items to those a user had interest previously or or items that interested a similar user. The difference between the two categories comes from how the features for the similarity calculations are obtained. In Collaborative Filtering the users and items characteristics are inferred from a user-item interaction metric, like ratings or quantity bought (used in this example). In Content Based approaches the used features are generally explicitly defined, like item color or type of material and user nationality and age. Therefore, Content Based approaches are highly dependent on extremely well curated data, and the more features available the better this models perform. In the [previous part](https://github.com/PMMAraujo/OnlineRetailII-ecommerce-project/blob/master/notebooks/eda_and_content_based.ipynb) I created some content based similarity inference systems only using the items names, they aren’t true recommender systems but still have some utility. Collaborative Filtering approaches do not need an extensive array of features available since it only depends on a user-item interaction metric. From it the user and item similarities can be inferred. Collaborative filtering is further divided in Memory and Model based methods. The divergency point between Memory and Model based methods is the data upon which the similarities between users and items are calculated. In Memory Based approaches the similarities are inferred from the user-item interaction directly while in Model based approaches there is an explicit modeling of the user-item interactions before the calculation of the similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Before doing any model implementations is always good to have a dummy baseline for comparison. First let’s divide the dataset in train and test (25%). The created baseline is simply the average of the trainset ratings for all the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T10:56:28.348668Z",
     "start_time": "2020-06-11T10:56:27.355502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline RMSE is: 1.0014571989371153\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader, Dataset,accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "file_path = './log_processed_df.csv'\n",
    "#file_path = 'drive/My Drive/Colab Notebooks/project_ecommerce/norm_processed_df.csv'\n",
    "\n",
    "reader = Reader(line_format='item rating user', sep=',', rating_scale=(0,10))\n",
    "\n",
    "data_log = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "\n",
    "trainset, testset = train_test_split(data_log, random_state=100,\n",
    "                                     test_size=0.25)\n",
    "\n",
    "\n",
    "real_test_y = [ x[2] for x in testset]\n",
    "average_train_preds =  [np.average(np.array([ x[2] for x in trainset.all_ratings()]))] * len(real_test_y)\n",
    "\n",
    "baseline_rmse = np.sqrt(mean_squared_error(real_test_y, average_train_preds))\n",
    "\n",
    "print(f\"The baseline RMSE is: {baseline_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let’s also take this opportunity to look at the data. Please notice that this dataset was well explored in the [first part](https://github.com/PMMAraujo/OnlineRetailII-ecommerce-project/blob/master/notebooks/eda_and_content_based.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T10:56:24.081217Z",
     "start_time": "2020-06-11T10:56:23.854703Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./log_processed_df.csv', header=None)\n",
    "df.columns = ['item', 'quantity_log', 'user']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Memory-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "So how does memory-based collaborative filtering work? Based on the user-item interactions, in this case buying quantities, a similarity matrix is built. The matrix can be built comparing all users or items to each other. The principle here is that users that buy similar items have similar buying patterns and are consequently similar for our modeling interests. The same idea is applied for the items, if bought by the same users their characteristics may be similar or related. An intuitive example can be demonstrated for movies data: user A likes horror movies so he always rates them high, but he doesn't like comedies so he rates them low. If enough users behave like user A the similarity calculation will group together horror movies away from comedies, even without any explicit knowledge of this characteristic.\n",
    "\n",
    "Having the similarity matrix built a model is applied, like K Nearest Neighbors (KNN), to identify closest data points to our user or item of interest. Then the closest data points are used to predict the quantitative feature at hand for missing entries in our user/item of interest. The way these predictions are built for the each missing entry can be a simple average of the value for the closest data points or, in a more complex fashion, the distance (1- similarity) of the closest data point to the user/item of interest can be used as weight for the creation of the predicted value.\n",
    "\n",
    "Overall the thinking process for item-based collaborative filtering is: People who bought this item also bought X. For user-item is: People similar to you bought X. Let’s implement these approaches to the dataset at hand to get a better grasp of these concepts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To implement the collaborative filtering approaches I’m going to use the package scikit surprise. The algorithm to calculate similarities that I'm going to use is KNNWithMeans. Scikit surprise has several k-NN inspired algorithms for collaborative filtering approaches: KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline. Here I'm going to only explore the KNNWithMeans algorithm, this decision was almost arbitrary based on my initial exploration and some use cases that I saw of this package usage. By no means I'm suggesting that this is the best algorithm for the job, that isn't what I'm trying to demonstrate here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's start by exploring the algorithm parameters. The package divides the hyperparameters for these algorithms in two levels, the first refers to the actual KNN method and how the predictions are calculated, being: 'k', 'min_k' and 'verbose'. The second level contains the similarity options and controls how the similarity matrix is built, here we have the 'name', 'user_based' and 'min_support'. The package documentation does a good job explaining this features (https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans), nevertheless here is a simplified explanation of them and their expected impact:\n",
    "\n",
    "- 'k' and 'min_k':  control the number of closest neighbors used by the method (max and min). Depending on the data set these have mid to high impact on the model. Basing a prediction on only one neighbor may generate a lot of uncertainty (high bias), therefore using multiple similar neighbors for this inference may generate more robust values. On the other hand if the prediction is based on the average of many neighbors the different contributions may dilute each other and in the end the output will be just an average (or close to it) of the data set (high variance);\n",
    "- 'verbose': simply controls how much text is written to the screen and has no impact in model performance;\n",
    "- 'name': is one of the most impactful features in terms of performance since it defines which method is going to be used to calculate the distance matrix between users or items. The three options are cosine distance, msd and pearson and no single one of them is the best for all approaches, one must test which one performs the best for the problem at hand;\n",
    "- 'user_based': is used to choose if we are going to calculate a distance matrix between users or between items, and consequently define if our approach is  user-item or item-item. This is mostly an approach decision and not an hyper-parameter;\n",
    "- 'mim_support' restricts the number of common items or users for the inference of the matrix similarities, less than this and the similarity is 0. This has a huge impact in the similarity matrix and the consequence KNN predictive method. It is a balance between dilution contributions (high value) and a high bias (low value), it needs to be properly tested and optimized. However, the pressure of the \"perfect\" value may generate smaller gains in the predictive capacity, instead it is more realistic to look for a reasonably good and stable value for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Item-item Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Starting with an item-item approach let's do a grid search with cross validation to infer the best hyperparameters for this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T11:02:36.058849Z",
     "start_time": "2020-06-11T10:57:28.621058Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "item_sim_options = {'name': ['cosine', 'msd', 'pearson'],\n",
    "                   'user_based': [False], # False because item-item approach\n",
    "                    'min_support': [1,2,5]}\n",
    "\n",
    "item_knn_param_grid = {'verbose': [False],\n",
    "                  'k':[20,40,60],\n",
    "                  'min_k':[1,2,5],\n",
    "                  'sim_options': item_sim_options\n",
    "                  }\n",
    "\n",
    "item_kwm_gs = GridSearchCV(KNNWithMeans, item_knn_param_grid,\n",
    "                           measures=['rmse', 'mae'], cv=5, n_jobs=4,\n",
    "                           refit=True) # output model retrain in entire data set\n",
    "\n",
    "item_kwm_gs.fit(data_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T21:26:39.437570Z",
     "start_time": "2020-06-11T21:26:39.430203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results from the grid_search_cv are:\n",
      "best score rmse: 0.5796235476542964\n",
      "best score mae: 0.4231853109804364\n",
      "best params rmse: {'verbose': False, 'k': 40, 'min_k': 1, 'sim_options': {'name': 'msd', 'user_based': False, 'min_support': 5}}\n",
      "best params mae: {'verbose': False, 'k': 20, 'min_k': 1, 'sim_options': {'name': 'msd', 'user_based': False, 'min_support': 5}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The results from the grid_search_cv are:\\n\\\n",
    "best score rmse: {item_kwm_gs.best_score['rmse']}\\n\\\n",
    "best score mae: {item_kwm_gs.best_score['mae']}\\n\\\n",
    "best params rmse: {item_kwm_gs.best_params['rmse']}\\n\\\n",
    "best params mae: {item_kwm_gs.best_params['mae']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "These results look promising when compared to the baseline. Especially because the approach used this time, the cross validation, is more robust than the simple train test split previously used. However, comparing this results is unfair because the validation strategy is different. One solution would be to train a model with the previously train-test-split and the new optimized parameters, however this approach has a major flaw commonly called data leakage. Basically the grid search saw all the data and optimized the parameters for it, so in theory a part of our model already contacted the data in the test set (from the train-test-split), consequently this test will be flawed. The proper approach would be to divide the data set in predefined k bins and do both the baseline and the grid search evaluation in the same bins in a cross validation manner. This would not be done here. In the end I just want a reference point, not a perfectly fair test, so for this end I'm happy with the current set-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T13:25:38.823347Z",
     "start_time": "2020-06-11T13:25:38.817670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4275, 4275)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.6637766 , 0.66253112, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.6637766 , 1.        , 0.81974447, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.66253112, 0.81974447, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_item_model = item_kwm_gs.best_estimator['rmse']\n",
    "item_sim_matrix = best_item_model.sim\n",
    "print(item_sim_matrix.shape)\n",
    "item_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The parameter .sim of the trained model contains the similarity matrix comparing all the items vs each other. Naturally its shape is (4275, 4275) since we have 4275 different items in the dataset. But is it any good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We can get the closest neighbors to each item, with the get_neighbors function. However, the scikit surprise methods generate, what they call, internal ids and for this request to the model there is the need to convert real item and user ids to the model internal ids. In the following example I infer the 3 closest neighbors to a randomly selected item. Then let's take those item descriptions and see if they are somewhat similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T11:02:39.172489Z",
     "start_time": "2020-06-11T11:02:38.279289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The clossest items to item with the ID 84913B are : ['90198B', '21617', '84920']\n",
      "The item has the name: MINT GREEN ROSE TOWEL\n",
      "The 3 clossest items to it have the names: VINTAGE ROSE BEAD BRACELET BLACK, 4 LILY  BOTANICAL DINNER CANDLES, and PINK FLOWER FABRIC PONY\n"
     ]
    }
   ],
   "source": [
    "trainset_full = data_log.build_full_trainset()\n",
    "\n",
    "rng = np.random.default_rng(seed=100)\n",
    "eg_inner_id = rng.choice(trainset_full.all_items()[-1], 1)\n",
    "eg_id = trainset_full.to_raw_iid(eg_inner_id[0])\n",
    "\n",
    "clossest_n = best_item_model.get_neighbors(eg_inner_id, 3)\n",
    "real_clossest_n = [trainset_full.to_raw_iid(x) for x in clossest_n]\n",
    "print(f\"The closest items to item with the ID {eg_id} are : {real_clossest_n}\")\n",
    "\n",
    "extra_info_df = pd.read_csv('extrainfo_log_processed_df.csv', header=None)\n",
    "\n",
    "print(f\"The item has the name: {extra_info_df[extra_info_df[0] == eg_id][3].values[0]}\")\n",
    "print(f\"The 3 closest items to it have the names: \\\n",
    "{extra_info_df[extra_info_df[0] == real_clossest_n[0]][3].values[0]}, \\\n",
    "{extra_info_df[extra_info_df[0] == real_clossest_n[1]][3].values[0]}, and \\\n",
    "{extra_info_df[extra_info_df[0] == real_clossest_n[2]][3].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Quite impressive that the names of these 4 items are somewhat related, the theme appears to be roses or flowers. Just a reminder that the name information was never given to the model, the only data the model contacted with was the user interactions with the items (purchasing quantities). To me this is a great indicator that the similarity matrix recreates reality, at least to some extent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now that I'm more confident in this similarity matrix and knowing that the KNN model outputs a decent rmse score when comparing to a baseline it's time to do some predictions. Let's get a user ID at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T11:19:59.767815Z",
     "start_time": "2020-06-11T11:19:59.757210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imp1884'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=10)\n",
    "eg_inner_id = rng.choice(trainset_full.all_items()[-1], 1)[0]\n",
    "eg_id = trainset_full.to_raw_uid(eg_inner_id)\n",
    "eg_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now let's predict the 5 items with higher value for the dependent variable for this user using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T13:19:21.756706Z",
     "start_time": "2020-06-11T13:19:21.743993Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(df, user_id, model, n_outs):\n",
    "    all_items = df['item'].unique()\n",
    "    already_pred = df[df['user'] == user_id]['item'].values\n",
    "    to_pred = [x for x in all_items if x not in already_pred]\n",
    "    \n",
    "    preds = {}\n",
    "    for item in to_pred:\n",
    "        this_pred = model.predict(user_id, item)[3]\n",
    "        preds[item] = this_pred\n",
    "    \n",
    "    pred_df = pd.DataFrame.from_dict(preds, orient='index')\n",
    "    pred_df.columns = ['pred']\n",
    "    output = pred_df.sort_values(by=['pred'], ascending=False).head(n=n_outs)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T13:26:04.400164Z",
     "start_time": "2020-06-11T13:26:04.277595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72732</th>\n",
       "      <td>7.813187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84760L</th>\n",
       "      <td>6.329721</td>\n",
       "      <td>LARGE HANGING GLASS+ZINC LANTERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72759</th>\n",
       "      <td>6.263398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20715</th>\n",
       "      <td>5.993961</td>\n",
       "      <td>LITTLE FLOWER SHOPPER BAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49031B</th>\n",
       "      <td>5.993961</td>\n",
       "      <td>CHROME EURO HOOK 20cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred                              name\n",
       "72732   7.813187                               NaN\n",
       "84760L  6.329721  LARGE HANGING GLASS+ZINC LANTERN\n",
       "72759   6.263398                               NaN\n",
       "20715   5.993961         LITTLE FLOWER SHOPPER BAG\n",
       "49031B  5.993961             CHROME EURO HOOK 20cm"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_results = get_predictions(df, eg_id, best_item_model, 5)\n",
    "\n",
    "names = []\n",
    "for iid in item_results.index:\n",
    "    name = extra_info_df[extra_info_df[0] == iid][3].values[0]\n",
    "    names.append(name)\n",
    "    \n",
    "item_results['name'] = names\n",
    "item_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Nice! According to this item-item collaborative model these are the 5 items that the user didn't interact with yet that will have a higher value for the dependent variable. But what is the dependent variable? In this case it is quantity bought, but it could be another metric. Let's say that we want to optimize for the amount of currency spent, the value predicted could be multiplied by the price per unit, please notice that the quantity was transformed using log +1. In this example the price functions like a set of weights that transform our prediction. This thinking process can be expanded and applied to other use cases like giving higher priority (higher weights) to the previous season items before the new one arrives to free storage space, or any other case of interest. With these methods one is not restricted to  only obtain the dependent variable, but also transform it depending on the objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## User-item Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The building process of the user-item collaborative filtering model with scikit surprise is the same as for the previously built item-item one, just remember to set the sim_option 'user_based' to False. Let's repeat the grid search parameter optimization problem and look at the different outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T15:31:51.683589Z",
     "start_time": "2020-06-11T13:58:04.022780Z"
    }
   },
   "outputs": [],
   "source": [
    "user_sim_options = {'name': ['cosine', 'msd', 'pearson'],\n",
    "                   'user_based': [True], \n",
    "                    'min_support': [1,2,5]}\n",
    "\n",
    "user_knn_param_grid = {'verbose': [False],\n",
    "                  'k':[20,40,60],\n",
    "                  'min_k':[1,2,5],\n",
    "                  'sim_options': user_sim_options\n",
    "                  }\n",
    "\n",
    "\n",
    "user_kwm_gs = GridSearchCV(KNNWithMeans, user_knn_param_grid,\n",
    "                           measures=['rmse', 'mae'], cv=5, n_jobs=4,\n",
    "                           refit=True) # output model retrain in entire data set\n",
    "\n",
    "user_kwm_gs.fit(data_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T21:26:54.281459Z",
     "start_time": "2020-06-11T21:26:54.274163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results from the grid_search_cv are:\n",
      "best score rmse: 0.5364497455230681\n",
      "best score mae: 0.37497963845840787\n",
      "best params rmse: {'verbose': False, 'k': 20, 'min_k': 2, 'sim_options': {'name': 'msd', 'user_based': True, 'min_support': 5}}\n",
      "best params mae: {'verbose': False, 'k': 20, 'min_k': 2, 'sim_options': {'name': 'msd', 'user_based': True, 'min_support': 5}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The results from the grid_search_cv are:\\n\\\n",
    "best score rmse: {user_kwm_gs.best_score['rmse']}\\n\\\n",
    "best score mae: {user_kwm_gs.best_score['mae']}\\n\\\n",
    "best params rmse: {user_kwm_gs.best_params['rmse']}\\n\\\n",
    "best params mae: {user_kwm_gs.best_params['mae']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Lets look at rmse output from different parameters within this grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T21:35:47.917173Z",
     "start_time": "2020-06-11T21:35:47.908299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaging the parameter \"min_k\" from 2 to 1 impacted the rmse in: -0.0002915195835179185\n",
      "Chaging the parameter \"name\" from \"msd\" to \"cosine\" impacted the rmse in: -0.031012899823172457\n",
      "Chaging the parameter \"min_support\" from 5 to 1 impacted the rmse in: -0.003194337883101195\n",
      "Chaging the parameter \"min_support\" from 5 to 2 impacted the rmse in: -0.0012495250511870282\n",
      "Chaging the parameter \"k\" from 20 to 40 impacted the rmse in: -0.0028650078782975763\n"
     ]
    }
   ],
   "source": [
    "user_kwm_gs.cv_results.keys()\n",
    "best_rmse = user_kwm_gs.best_score['rmse']\n",
    "r1 = user_kwm_gs.cv_results['mean_test_rmse'][5]\n",
    "p1 = user_kwm_gs.cv_results['params'][5]\n",
    "r2 = user_kwm_gs.cv_results['mean_test_rmse'][11]\n",
    "p2 = user_kwm_gs.cv_results['params'][11]\n",
    "r3 = user_kwm_gs.cv_results['mean_test_rmse'][12]\n",
    "p3 = user_kwm_gs.cv_results['params'][12]\n",
    "r4 = user_kwm_gs.cv_results['mean_test_rmse'][13]\n",
    "p4 = user_kwm_gs.cv_results['params'][13]\n",
    "r5 = user_kwm_gs.cv_results['mean_test_rmse'][41]\n",
    "p5 = user_kwm_gs.cv_results['params'][41]\n",
    "\n",
    "print(f'Changing the parameter \"min_k\" from 2 to 1 impacted the rmse in: {best_rmse - r1}')\n",
    "print(f'Changing the parameter \"name\" from \"msd\" to \"cosine\" impacted the rmse in: {best_rmse - r2}')\n",
    "print(f'Changing the parameter \"min_support\" from 5 to 1 impacted the rmse in: {best_rmse - r3}')\n",
    "print(f'Changing the parameter \"min_support\" from 5 to 2 impacted the rmse in: {best_rmse - r4}')\n",
    "print(f'Changing the parameter \"k\" from 20 to 40 impacted the rmse in: {best_rmse - r5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "As it is possible to understand from these differences in the RMSE metric some hyperparameters had a bigger impact than others in the model performance. Namely, the methods of distance calculation (\"name\") appears to have a great impact while \"min_K\" seems to only influence in a minor way or indirectly when combined with other parameters.\n",
    "Grid search cross validation was a big waste for this example, the improvements seen on the model were only minor and the time it took to achieve the best result was almost 50 times the  time for training a model with the default parameters. Nevertheless, in some specific cases hyperparameter optimization may be essential in separating an ok model from a great one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T13:56:18.917542Z",
     "start_time": "2020-06-11T13:56:18.908264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity matix shape is: (7019, 7019)\n"
     ]
    }
   ],
   "source": [
    "best_user_model = user_kwm_gs.best_estimator['rmse']\n",
    "user_sim_matrix = best_user_model.sim\n",
    "print(f\"The similarity matrix shape is: {user_sim_matrix.shape}\")\n",
    "#user_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "As expected the similarity matrix is 7019 by 7019, since the dataset has 7019 different users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47503J</th>\n",
       "      <td>1.712326</td>\n",
       "      <td>SET/3 FLORAL GARDEN TOOLS IN BAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85017C</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>ENVELOPE 50 CURIOUS IMAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37422</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>WHITE WITH BLACK CATS BOWL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37462B</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>PET MUG, BUDGIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37489C</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>GREEN/BLUE FLOWER DESIGN BIG MUG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred                              name\n",
       "47503J   1.712326  SET/3 FLORAL GARDEN TOOLS IN BAG\n",
       "85017C   0.693147        ENVELOPE 50 CURIOUS IMAGES\n",
       "37422    0.693147        WHITE WITH BLACK CATS BOWL\n",
       "37462B   0.693147                   PET MUG, BUDGIE\n",
       "37489C   0.693147  GREEN/BLUE FLOWER DESIGN BIG MUG"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_results = get_predictions(df, eg_id, best_user_model, 5)\n",
    "\n",
    "names = []\n",
    "for iid in user_results.index:\n",
    "    name = extra_info_df[extra_info_df[0] == iid][3].values[0]\n",
    "    names.append(name)\n",
    "    \n",
    "user_results['name'] = names\n",
    "user_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T13:41:19.483031Z",
     "start_time": "2020-06-11T13:41:18.978868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The items suggested user the item-item approach are: ['72732', '84760L', '72759', '20715', '49031B']\n",
      "The items suggested user the user-item approach are: ['47503J ', '85017C', '37422', '37462B', '37489C']\n"
     ]
    }
   ],
   "source": [
    "user_results = get_predictions(df, eg_id, best_user_model, 5)\n",
    "\n",
    "print(f\"The items suggested user the item-item approach are: {list(item_results.index)}\\n\\\n",
    "The items suggested user the user-item approach are: {list(user_results.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T13:40:57.675845Z",
     "start_time": "2020-06-11T13:40:57.671693Z"
    }
   },
   "source": [
    "So these item suggestions are quite different, which highlights the importance of the methodology in recommender systems. The answer to the question \"which one is better?\" depends greatly on the objective, that's why having well defined objectives and metrics is extremely valuable. Moreover, it is possible to combine several models to achieve hybrid solutions, which may lead to more robust answers. It is possible to create large amounts of models but if those models don't solve a specific problem their usefulness is questionable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T13:32:08.328160Z",
     "start_time": "2020-06-11T13:32:08.320960Z"
    }
   },
   "source": [
    "To wrap up, here I showed that memory-based collaborative models can indeed pick-up patterns from the dataset. The provided dependent variable doesn't need to be a rating, in theory it can be any metric of user interactions with items.\n",
    "There is more to collaborative filtering than memory-based models, so next let's apply a model-based solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "As previously talked about in model-based approaches the inference of the user and items characteristics is not done directly from the user-item interaction metrics. Instead a model is applied to this data and from the output of said model the inference of characteristics is made. This methodology is extremely useful because the user-item interactions matrix is sparse, meaning many users never interacted with the majority of items. The method that I'm going to apply here to \"reduce the dimensionality\" of the user-item matrix is Single Vector Decompositions (SVD) as implemented in the scikit surprise package. And the correct term for this \"dimensionality reduction\" is matrix factorization. When doing matrix multiplication we have two matrices of compatible shapes, let's say one is 4 by 3 and the other 3 by 2, ending up with a new matrix which in our example would be 4 by 2. To get a visualization of this I strongly recommend the website [matrixmultiplication](http://matrixmultiplication.xyz/). In matrix factorization we are going the other way around, from the 4 by 2 matrix we want to obtain the 4 by 3 and the 3 by 2 matrices, and depending on the method applied some added bias. Baptiste Rocca made an [amazing schematic representation](https://miro.medium.com/max/2000/1*E9EE5LXxty1EB8fn_s1jkQ@2x.png) of this in his [blog post](https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada), I can't stress enough that if you are interested in this field to go and read that amazing blog post.\n",
    "With this process two matrices are generated, one corresponding to the users and another to the items. Therefore, each row in the created  users matrix is an embedding representation of that user, the same is valid for items. The embeddings can be seen as a list of latent characteristics of the user or item that the model found, however these most likely do not correspond to real features like color or type. To sum-up, this approach can be seen as the creation of embeddings representations, which are then used to infer similarities among users or items. \n",
    "\n",
    "Like in the memory based examples here I'm not trying to claim SVD is the best algorithm for this purpose, it is certainly one of the most populars if not the most popular. In scikit surprise package there are other implementations to perform matrix factorization like SVDpp and NMF.\n",
    "Before, implementing SVD in sckit surprise lets look at some of its hyperparameters:\n",
    " - n_factors: this defines the shape of the user and items matrices created. The length of each embedding created is going to the number defined here. The temptation is to define a large value for this parameter, in order to infer as much as possible from the data, however that may result in overfitting;\n",
    " - n_epochs: number of times the optimization procedure is going to see the data. This is highly correlated with the learning and regularization rates. Doesn’t have and direct impact on the model inference, however it longer iterations give the model more opportunities to learn (or memorize the train set);\n",
    " - biased: if set to true the matrix factorization defaults to Probabilistic Matrix Factorization;\n",
    " - init_mean & init_std_dev: the initial vectors for the created matrices are generated at \"random\", which is not completely true because they are sampled from a designated normal distribution. These two parameters define the characteristics of said normal distribution;\n",
    " - lr_all: this function is like the step size of the optimization process. If too big leads to instability, is too small takes more time to converge (more epochs);\n",
    " - reg_all: regularization is applied to decrease the overfitting potential of an optimization procedure. These methods, in theory, increase the algorithm performance in unseen data (test or validation set), in other other help the creating models that generalize better;\n",
    " - lr_* & reg_*: these parameters control the learning rate and regularization for specific parameters instead of applying the same to all (like when using lr all and reg_all). I will not play with these;\n",
    " - random_state: it is always good to define a random state in order to ensure reproducibility. These processes are stochastic, meaning that \"random\" picked values may have a considerable impact on the model. This should not be optimized like other hyperparameters;\n",
    " - verbose: just controls how much is optuted to the screen during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's do a grid search to infer the best parameters, but instead of optimizing everything let's set the number of epochs to 10 and see which combination of learning rate, regularization and number of factors works the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-06-11T15:21:50.598381Z",
     "start_time": "2020-06-11T15:19:20.500966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5387568817943309\n",
      "{'n_epochs': 10, 'n_factors': 200, 'lr_all': 0.008, 'random_state': 100, 'reg_all': 0.02, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "param_grid = {\n",
    "    \"n_epochs\": [10],\n",
    "    \"n_factors\": [50, 100, 200],\n",
    "    \"lr_all\": [0.002, 0.005, 0.008],\n",
    "    \"random_state\":[100],\n",
    "    \"reg_all\": [0.01, 0.02, 0.05],\n",
    "    \"verbose\": [False],\n",
    "}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=5, refit=True,\n",
    "                  n_jobs=4)\n",
    "\n",
    "gs.fit(data_log)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])\n",
    "\n",
    "best_model_based_model = gs.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>n_factors</th>\n",
       "      <th>lr_all</th>\n",
       "      <th>reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.538757</td>\n",
       "      <td>200</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.539269</td>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0.540253</td>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0.540699</td>\n",
       "      <td>200</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.542383</td>\n",
       "      <td>50</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0.544746</td>\n",
       "      <td>50</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_rmse  mean_test_rmse  n_factors  lr_all  reg_all\n",
       "25               1        0.538757        200   0.008     0.02\n",
       "15               2        0.539269        100   0.008     0.01\n",
       "16               3        0.540253        100   0.008     0.02\n",
       "24               4        0.540699        200   0.008     0.01\n",
       "6                5        0.542383         50   0.008     0.01\n",
       "7                6        0.544746         50   0.008     0.02"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_df = pd.DataFrame.from_dict(gs.cv_results)[['rank_test_rmse', 'mean_test_rmse']]\n",
    "params_df = pd.DataFrame.from_dict(gs.cv_results['params'])\n",
    "\n",
    "gs_df_final = gs_df.join(params_df).drop(['n_epochs', 'random_state', 'verbose'], axis=1).sort_values(by=['rank_test_rmse'])\n",
    "gs_df_final.head(n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Without surprise the best combination of parameters always involved (6 in the first 6) the highest learning rate (0.08). This, most likely, indicates that the model needs to be trained for a long period (more epochs). The top 3 results are close together, the difference among them is neglectable. It seems intuitive to me that models with a higher number of factors, and consequently more parameters, will benefit from more regularization to avoid overfitting.\n",
    "Although I recognize that this model could use some improvements I'm going to stay with it for now and analyse its outputs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The two matrices created, one for users and the other for items have the shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users matrix shape: (7019, 200)\n",
      "Items matrix shape: (4275, 200)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Users matrix shape: {best_model_based_model.pu.shape}\")\n",
    "print(f\"Items matrix shape: {best_model_based_model.qi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Being the User matrix the number of users vs the n_factors and the items matrix the number of items vs n_components. As previously mentioned the 200 points of each embedding can be seen as latent characteristics that the model inferred for each item or user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Finally let’s get the top 5 predictions for the test id using the previously written function, but this time with the model-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16033</th>\n",
       "      <td>4.371850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84568</th>\n",
       "      <td>3.681382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16259</th>\n",
       "      <td>3.632351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17084R</th>\n",
       "      <td>3.603174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16169C</th>\n",
       "      <td>3.482402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred\n",
       "16033   4.371850\n",
       "84568   3.681382\n",
       "16259   3.632351\n",
       "17084R  3.603174\n",
       "16169C  3.482402"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = get_predictions(df, eg_id, best_model_based_model, 5)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Scikit surprise makes it easy to implement collaborative filtering models, however the way that the dataset is handled internally by this package makes it hard (or even impossible) to have a train test split followed by the division of the train set into validation and train. Overall, I think the package achieves what it proposes to do and therefore I recommend it to anyone trying to apply Collaborative filtering methods for the first time. It has some api differences to other packages well used for machine learning, like sklearn, but the documentation is enough to grasp what is going on.\n",
    "It was very interesting to work with this dataset, the data transformations that I did initially like converting the quantities values to log +1 certainly had a huge impact in the models and it would be interesting to evaluate the performance of the models with other data transformations. Maybe for a part three of this project! However, for now this is it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
